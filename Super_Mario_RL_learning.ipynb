{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328e1ca0",
   "metadata": {},
   "source": [
    "# 1. Install and import the game and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30cfc0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nes-py in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (8.2.1)\n",
      "Requirement already satisfied: gym>=0.17.2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py) (1.24.4)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py) (4.66.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from gym>=0.17.2->nes-py) (1.3.0)\n",
      "Requirement already satisfied: future in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from pyglet<=1.5.21,>=1.4.0->nes-py) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tqdm>=4.48.2->nes-py) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting gym-super-mario-bros==7.3.0\n",
      "  Using cached gym_super_mario_bros-7.3.0-py2.py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: nes-py>=8.0.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from gym-super-mario-bros==7.3.0) (8.2.1)\n",
      "Requirement already satisfied: gym>=0.17.2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.24.4)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (4.66.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from gym>=0.17.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.3.0)\n",
      "Requirement already satisfied: future in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from pyglet<=1.5.21,>=1.4.0->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tqdm>=4.48.2->nes-py>=8.0.0->gym-super-mario-bros==7.3.0) (0.4.6)\n",
      "Using cached gym_super_mario_bros-7.3.0-py2.py3-none-any.whl (198 kB)\n",
      "Installing collected packages: gym-super-mario-bros\n",
      "  Attempting uninstall: gym-super-mario-bros\n",
      "    Found existing installation: gym-super-mario-bros 7.4.0\n",
      "    Uninstalling gym-super-mario-bros-7.4.0:\n",
      "      Successfully uninstalled gym-super-mario-bros-7.4.0\n",
      "Successfully installed gym-super-mario-bros-7.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: setuptools==65.5.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (65.5.0)\n",
      "Requirement already satisfied: wheel<0.40.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (0.38.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gym==0.21.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from gym==0.21.0) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from gym==0.21.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stable-baselines3==1.6.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (1.6.0)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2.3.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (3.7.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (4.9.0.80)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (0.7.4)\n",
      "Requirement already satisfied: autorom~=0.4.2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (0.4.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (10.3.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (2.14.0)\n",
      "Requirement already satisfied: protobuf~=3.19.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (3.19.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from stable-baselines3[extra]==1.6.0) (5.9.8)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]==1.6.0) (6.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]==1.6.0) (7.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (4.66.4)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (1.63.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (65.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (3.0.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (0.38.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2021.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from pandas->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from pandas->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2024.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from importlib-metadata>=4.10.0->ale-py==0.7.4->stable-baselines3[extra]==1.6.0) (3.17.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from requests->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (2.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from click->autorom~=0.4.2->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]==1.6.0) (0.4.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from sympy->torch>=1.11->stable-baselines3==1.6.0->stable-baselines3[extra]==1.6.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\john\\anaconda3\\envs\\super_mario_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->stable-baselines3[extra]==1.6.0) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nes-py\n",
    "%pip install gym-super-mario-bros==7.3.0\n",
    "%pip install setuptools==65.5.0 \"wheel<0.40.0\"\n",
    "%pip install gym==0.21.0\n",
    "%pip install stable-baselines3[extra]==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9d9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 30.7/199.4 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 81.9/199.4 kB 770.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 174.1/199.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 kB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9988a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the super mario game in the notebook\n",
    "import gym_super_mario_bros\n",
    "\n",
    "#Import the Joypad wrapper in the notebook\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "#Import the simple controls so that the model just needs to control some movements of our agent (here Mario)\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc85c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changes the game from colour image (RGB) to grayscale so that our processing becomes faster as we need to deal with less data \n",
    "from gym.wrappers import GrayScaleObservation, ResizeObservation   \n",
    "\n",
    "#VecFrameStack allows us to work with our stacked enviroments by letting us know the information of previous frames. DummyVecEnv transforms our model so that we can pass it to our AI model. \n",
    "from stable_baselines3.common.vec_env import VecFrameStack, SubprocVecEnv, VecMonitor, VecNormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685762d",
   "metadata": {},
   "source": [
    "# 2. Preprocessing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7b665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Box\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SkipWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_stack=4, n_skip=2):\n",
    "        super().__init__(env)\n",
    "        self.n_stack = n_stack\n",
    "        self.n_skip = n_skip\n",
    "        self.height = 84\n",
    "        self.width = 84\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=0, high=255, shape=(self.height, self.width, self.n_stack), dtype=np.uint8\n",
    "        )\n",
    "        self.frame_stack = np.zeros((self.height, self.width, (self.n_stack-1)*self.n_skip+1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        self.frame_stack[:,:,1:] = self.frame_stack[:,:,:-1] # shift frame_stack by 1\n",
    "        self.frame_stack[:,:,0] = obs[:,:,0] # add current frame to stack\n",
    "        obs = self.frame_stack[:,:,::self.n_skip]\n",
    "        return obs\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        obs = obs[:,:,0]\n",
    "        self.frame_stack = np.zeros((self.height, self.width, (self.n_stack-1)*self.n_skip+1), dtype=np.uint8)\n",
    "        for i in range(self.frame_stack.shape[-1]):\n",
    "            self.frame_stack[:,:,i] = obs\n",
    "        obs = self.frame_stack[:,:,::self.n_skip]\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da253474",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = ResizeObservation(env, (84, 84))\n",
    "env = SkipWrapper(env, n_stack=4, n_skip=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c66e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec28a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of trained and logged files \n",
    "CHECKPOINT_DIR = './train/WithSkipWrapper'\n",
    "LOG_DIR = './logs'\n",
    "HPO_LOG_DIR = './opt_logs'\n",
    "HPO_CHECKPOINT_DIR = './opt_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a15c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(seed, env_name):\n",
    "    def init():\n",
    "        env = gym_super_mario_bros.make(env_name)\n",
    "        env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "        env = GrayScaleObservation(env, keep_dim=True)\n",
    "        env = ResizeObservation(env, (84, 84))\n",
    "        env = SkipWrapper(env, n_stack=4, n_skip=4)\n",
    "        env.seed(seed)\n",
    "\n",
    "        return env\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fe07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SubprocVecEnv([make_env(i, \"SuperMarioBros-1-1-v0\") for i in range(6)])\n",
    "env = VecMonitor(env, LOG_DIR)\n",
    "env = VecNormalize(env, clip_obs=255, clip_reward=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c14ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]\n",
       "\n",
       " [[0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  ...\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]\n",
       "  [0 0 0 0]]], [[[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " ...\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]\n",
       "\n",
       " [[255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  ...\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]\n",
       "  [255 255 255 255]]], (84, 84, 4), uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "355badc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOOP'],\n",
       " ['right'],\n",
       " ['right', 'A'],\n",
       " ['right', 'B'],\n",
       " ['right', 'A', 'B'],\n",
       " ['A'],\n",
       " ['left']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980aec89",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7337c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the optimization frame - HPO\n",
    "# import optuna\n",
    "# Bring in the eval policy method for metric calculation\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gc\n",
    "# Import os for file path management\n",
    "import os\n",
    "\n",
    "# Import PPO algorithm to train our model\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import Base Callback for saving models and to continue from there\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a813dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return test hyperparameters - define the object function\n",
    "\n",
    "def optimize_ppo(trial):\n",
    "    return {\n",
    "        'batch_size': trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512]),\n",
    "        'n_steps': trial.suggest_categorical(\"n_steps\", [512, 1024, 2048, 4096]), # \n",
    "        'gamma': trial.suggest_float(\"gamma\", 0.8, 0.999, log=True),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 5e-6, 0.001, log=True),\n",
    "        'ent_coef': trial.suggest_float(\"ent_coef\", 0.0001, 0.1, log=True),\n",
    "        'clip_range': trial.suggest_categorical(\"clip_range\", [0.1, 0.2, 0.3]),\n",
    "        'n_epochs': trial.suggest_int(\"n_epochs\", 1, 10),\n",
    "        'gae_lambda': trial.suggest_float(\"gae_lambda\", 0.8, 1, log=True),\n",
    "        'max_grad_norm': trial.suggest_categorical(\"max_grad_norm\", [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 5]),\n",
    "        'vf_coef': trial.suggest_float(\"vf_coef\", 0.001, 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6787a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_agent(trial):\n",
    "    try:\n",
    "        model_params = optimize_ppo(trial)\n",
    "        \n",
    "        env = SubprocVecEnv([make_env(i) for i in range(6)])\n",
    "        env = VecMonitor(env, \"./opt_logs\")\n",
    "        env = VecNormalize(env, clip_obs=255, clip_reward=15)\n",
    "        # 5. Stack 4 frames of our environment and channels_order=\"last\" is for stacking along the last dimension\n",
    "        env = VecFrameStack(env, 4, channels_order=\"last\")\n",
    "        \n",
    "        # Create PPO\n",
    "        model = PPO('CnnPolicy', env, tensorboard_log='./opt_logs', verbose=0, **model_params)\n",
    "        model.learn(total_timesteps=500000)\n",
    "\n",
    "        # Evaluate model\n",
    "        mean_reward, _ = evaluate_policy(model, env, n_eval_episodes=6)\n",
    "\n",
    "        SAVE_PATH = os.path.join('./opt_train', 'trial_{}_best_model'.format(trial.number))\n",
    "        model.save(SAVE_PATH)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        return mean_reward\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-27 10:17:00,835] A new study created in memory with name: no-name-1bed4b09-223c-4c4e-bcfd-7a5700b62b32\n",
      "[I 2024-04-27 11:14:32,391] Trial 0 finished with value: 652.0 and parameters: {'batch_size': 512, 'n_steps': 4096, 'gamma': 0.9883036470196476, 'learning_rate': 8.248052180662126e-05, 'ent_coef': 0.0033192103311894183, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.8919467930908171, 'max_grad_norm': 0.7, 'vf_coef': 0.7984597981165633}. Best is trial 0 with value: 652.0.\n",
      "[I 2024-04-27 12:02:37,900] Trial 1 finished with value: 1412.0 and parameters: {'batch_size': 32, 'n_steps': 512, 'gamma': 0.9338680619365152, 'learning_rate': 0.0001268588513340457, 'ent_coef': 0.0009831640718997235, 'clip_range': 0.3, 'n_epochs': 6, 'gae_lambda': 0.8439412903910558, 'max_grad_norm': 0.7, 'vf_coef': 0.22397706946296733}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 12:31:02,059] Trial 2 finished with value: 680.0 and parameters: {'batch_size': 32, 'n_steps': 4096, 'gamma': 0.9643015825363668, 'learning_rate': 6.843644777253488e-06, 'ent_coef': 0.0019694749919515913, 'clip_range': 0.1, 'n_epochs': 1, 'gae_lambda': 0.8894228024565385, 'max_grad_norm': 5, 'vf_coef': 0.07568565582751353}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 13:05:37,355] Trial 3 finished with value: 1119.0 and parameters: {'batch_size': 32, 'n_steps': 512, 'gamma': 0.8619924076096134, 'learning_rate': 8.64880408411138e-05, 'ent_coef': 0.00235246884354979, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.9364556125918055, 'max_grad_norm': 1, 'vf_coef': 0.8597824546071492}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 14:07:11,087] Trial 4 finished with value: 1221.0 and parameters: {'batch_size': 64, 'n_steps': 2048, 'gamma': 0.9405735800968994, 'learning_rate': 0.00028974629663958124, 'ent_coef': 0.08125029082885399, 'clip_range': 0.1, 'n_epochs': 9, 'gae_lambda': 0.9324268805112106, 'max_grad_norm': 1, 'vf_coef': 0.5122203931447346}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 14:30:32,400] Trial 5 finished with value: 737.0 and parameters: {'batch_size': 128, 'n_steps': 4096, 'gamma': 0.8377504853321033, 'learning_rate': 0.0004224936230191382, 'ent_coef': 0.0005015179775544449, 'clip_range': 0.1, 'n_epochs': 1, 'gae_lambda': 0.825392619675884, 'max_grad_norm': 2, 'vf_coef': 0.6746752063099325}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 15:00:12,232] Trial 6 finished with value: 737.0 and parameters: {'batch_size': 16, 'n_steps': 4096, 'gamma': 0.8716968564786994, 'learning_rate': 0.00013625446227934391, 'ent_coef': 0.01219991970117021, 'clip_range': 0.3, 'n_epochs': 1, 'gae_lambda': 0.9983647494739398, 'max_grad_norm': 1, 'vf_coef': 0.3989772308611051}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 15:48:03,784] Trial 7 finished with value: 530.0 and parameters: {'batch_size': 32, 'n_steps': 1024, 'gamma': 0.9048936799440385, 'learning_rate': 0.0008928429441898327, 'ent_coef': 0.0016960548720445863, 'clip_range': 0.1, 'n_epochs': 8, 'gae_lambda': 0.902913150668114, 'max_grad_norm': 5, 'vf_coef': 0.24251652845359672}. Best is trial 1 with value: 1412.0.\n",
      "[I 2024-04-27 16:03:51,479] Trial 8 finished with value: 1881.0 and parameters: {'batch_size': 32, 'n_steps': 2048, 'gamma': 0.9740900687762593, 'learning_rate': 2.8050769830322757e-05, 'ent_coef': 0.00025465720381928695, 'clip_range': 0.3, 'n_epochs': 2, 'gae_lambda': 0.8123425488808541, 'max_grad_norm': 0.8, 'vf_coef': 0.8399612265695744}. Best is trial 8 with value: 1881.0.\n",
      "[I 2024-04-27 16:15:39,396] Trial 9 finished with value: 737.0 and parameters: {'batch_size': 128, 'n_steps': 512, 'gamma': 0.8621963110573468, 'learning_rate': 0.0005078566132656594, 'ent_coef': 0.0021524885389658213, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.8868390815036991, 'max_grad_norm': 0.3, 'vf_coef': 0.9595112433944338}. Best is trial 8 with value: 1881.0.\n",
      "[I 2024-04-27 16:40:51,484] Trial 10 finished with value: 741.0 and parameters: {'batch_size': 256, 'n_steps': 2048, 'gamma': 0.8092691217791166, 'learning_rate': 1.6123089294685322e-05, 'ent_coef': 0.00011439953220511596, 'clip_range': 0.2, 'n_epochs': 4, 'gae_lambda': 0.8022664175959311, 'max_grad_norm': 0.8, 'vf_coef': 0.630781178268567}. Best is trial 8 with value: 1881.0.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(optimize_agent, n_trials=100, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef4442",
   "metadata": {},
   "source": [
    "# 3. Build and Train the RL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd48bfa",
   "metadata": {},
   "source": [
    "##### To train our RL model(Our AI) we are going to use PPO (Proximal Policy Optimization) Algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f10e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the clipping range\n",
    "def custom_clip_range(a):\n",
    "    a = 0.2\n",
    "    return a  \n",
    "\n",
    "#Set the learning rate\n",
    "def linear_schedule(initial_value: float):\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0adfe4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the trainnig files and logging files location\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        # Save the model and track training progress\n",
    "        if self.num_timesteps % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.num_timesteps))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "\n",
    "# # Check if a previously trained model exists\n",
    "# if os.path.exists('./train/best_model.zip'):\n",
    "#     # Load the pre-trained model\n",
    "#     model_start = PPO.load('./train/best_model.zip', env, tensorboard_log=LOG_DIR, custom_objects={'clip_range': custom_clip_range, 'learning_rate':linear_schedule(0.0001)})\n",
    "    \n",
    "#     # Get the total number of steps completed during the previous training\n",
    "#     total_steps_completed = model_start.num_timesteps\n",
    "    \n",
    "#     model = PPO.load('./train/best_model.zip', env, tensorboard_log=LOG_DIR, custom_objects={'clip_range': custom_clip_range, 'learning_rate':linear_schedule(0.0001)})\n",
    "\n",
    "#     # Adjust the starting step count and the total number of training steps\n",
    "#     starting_step = total_steps_completed + 1\n",
    "#     total_training_steps = starting_step + 100000  # Resume training for 100,000 steps\n",
    "# else:\n",
    "#     # Create a new model if no pre-trained model exists\n",
    "#     model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=linear_schedule(0.0001), n_steps=512)\n",
    "    \n",
    "    \n",
    "#     # Set the starting step count and the total number of training steps\n",
    "#     starting_step = 1\n",
    "#     total_training_steps = 100000  # Train for 100,000 steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d7fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'learning_rate': linear_schedule(1e-5),\n",
    "    'n_steps': 512,\n",
    "    'batch_size': 64,\n",
    "    'n_epochs': 10,\n",
    "    'gamma': 0.99,\n",
    "    'gae_lambda': 0.95,\n",
    "    'clip_range': 0.2,\n",
    "    'normalize_advantage': True,\n",
    "    'ent_coef': 0,\n",
    "    'vf_coef': 0.5,\n",
    "    'max_grad_norm': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23efb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO.load(os.path.join(CHECKPOINT_DIR, 'best_model_2000040'), env, tensorboard_log=LOG_DIR)\n",
    "model = PPO('CnnPolicy', env, env_ewc = env,tensorboard_log='./logs/WithSkipWrapper/linear_learning_rate', verbose=0, **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa85ca96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticCnnPolicy(\n",
       "  (features_extractor): NatureCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential()\n",
       "    (value_net): Sequential()\n",
       "  )\n",
       "  (action_net): Linear(in_features=512, out_features=7, bias=True)\n",
       "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0629eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of trained and logged files \n",
    "CHECKPOINT_DIR = './train/WithSkipWrapper/model_4'\n",
    "LOG_DIR = './logs'\n",
    "HPO_LOG_DIR = './opt_logs'\n",
    "HPO_CHECKPOINT_DIR = './opt_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e77e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call back the trained and logged model after every 100002 steps (takes 150MB space for one run logged data for 5k steps) and save to CHECKPOINT_DIR.\n",
    "callback = TrainAndLoggingCallback(check_freq=100002, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0babee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.learning_rate = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3264f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(os.path.join(CHECKPOINT_DIR, 'best_model_1200024'), env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7252b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "717db71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90751202",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Train the AI model, this is where the AI model starts to learn\n",
    "t_start = time.time()\n",
    "\n",
    "model.learn(total_timesteps=10e6, callback=callback, tb_log_name=\"model_4\", reset_num_timesteps=False)\n",
    "\n",
    "t_elapsed = time.time() - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e6e9e",
   "metadata": {},
   "source": [
    "# 4. Testing the model (AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee408da",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the new combined model\n",
    "combined_model = PPO.load('./train/best_model_200000', custom_objects={'clip_range': custom_clip_range, 'learning_rate': linear_schedule(0.0001)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b2878",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Starting our game\n",
    "state = env.reset()\n",
    "\n",
    "#Loop through the game\n",
    "while True:\n",
    "    # we are getting two values of which we need only one, so we put a underscore to just assign it the extra value\n",
    "    action, _ = combined_model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858753b",
   "metadata": {},
   "source": [
    "To stop the loop, that is the game, press the \"interrupt the kernel\" button shown by a black square next to \"Run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40fb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mzmq.error.ZMQError: Address in use (addr='tcp://127.0.0.1:9002'). \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#To close the game environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_mario_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
