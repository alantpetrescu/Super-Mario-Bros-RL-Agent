{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and import the game and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the super mario game in the notebook\n",
    "import gym_super_mario_bros\n",
    "\n",
    "#Import the Joypad wrapper in the notebook\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "#Import the simple controls so that the model just needs to control some movements of our agent (here Mario)\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "m = torch.distributions.Categorical(logits=torch.tensor([[0,1,2], [2,3,4], [3,4,5]]))\n",
    "m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the game from colour image (RGB) to grayscale so that our processing becomes faster as we need to deal with less data \n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces import Box\n",
    "\n",
    "# VecFrameStack allows us to work with our stacked enviroments by letting us know the information of previous frames. DummyVecEnv transforms our model so that we can pass it to our AI model. \n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecMonitor\n",
    "\n",
    "# Import the Super Mario RAM utils\n",
    "from Super_Mario_RAM_utils import MarioRAMGrid\n",
    "\n",
    "# Import Numpy for mathematics\n",
    "import numpy as np\n",
    "\n",
    "# Import pyplot for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import time for measuring the training time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the optimization frame - HPO\n",
    "# import optuna\n",
    "# Bring in the eval policy method for metric calculation\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gc\n",
    "# Import os for file path management\n",
    "import os\n",
    "\n",
    "# Import PPO algorithm to train our model\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import Base Callback for saving models and to continue from there\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAMAndSkipWrapper(ObservationWrapper):\n",
    "    def __init__(self, env, n_stack=4, n_skip=2):\n",
    "        super().__init__(env)\n",
    "        self.n_stack = n_stack\n",
    "        self.n_skip = n_skip\n",
    "        self.width = 16\n",
    "        self.height = 13\n",
    "        self.observation_space = Box(\n",
    "            low=-2, high=2, shape=(self.height, self.width, self.n_stack), dtype=np.int8\n",
    "        )\n",
    "        \n",
    "        self.frame_stack = np.zeros((self.height, self.width, (self.n_stack-1)*self.n_skip+1), dtype=np.int8)\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        grid = MarioRAMGrid(self.env)\n",
    "        frame = grid.rendered_screen # The RAM map for the current frame\n",
    "        \n",
    "        self.frame_stack[:,:,1:] = self.frame_stack[:,:,:-1] # Shift frame_stack by 1 to the right\n",
    "        self.frame_stack[:,:,0] = frame # Add the current frame to stack on the left\n",
    "        obs = self.frame_stack[:,:,::self.n_skip]\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        self.frame_stack = np.zeros((self.height, self.width, (self.n_stack-1)*self.n_skip+1), dtype=np.int8)\n",
    "        grid = MarioRAMGrid(self.env)\n",
    "        frame = grid.rendered_screen # 2d array\n",
    "\n",
    "        for i in range(self.frame_stack.shape[-1]):\n",
    "            self.frame_stack[:,:,i] = frame\n",
    "\n",
    "        obs = self.frame_stack[:,:,::self.n_skip]\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_weights = []\n",
    "batch_weights += [2] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(seed, env_name, n_stack, n_skip):\n",
    "    def init():\n",
    "        env = gym_super_mario_bros.make(env_name)\n",
    "        env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "        env = RAMAndSkipWrapper(env, n_stack=n_stack, n_skip=n_skip)\n",
    "\n",
    "        return env\n",
    "    \n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of trained and logged files \n",
    "CHECKPOINT_DIR = './train/WithSkipWrapper'\n",
    "LOG_DIR = './logs'\n",
    "HPO_LOG_DIR = './opt_logs'\n",
    "HPO_CHECKPOINT_DIR = './opt_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"SuperMarioBros-1-2-v0\"\n",
    "n_stack = 4\n",
    "n_skip = 4\n",
    "\n",
    "env = make_env(0, env_name, n_stack, n_skip)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 16, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test env_wrap\n",
    "done = True\n",
    "for i in range(150):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, n_stack, figsize=(14,10))\n",
    "for i in range(n_stack):\n",
    "    ax[i].imshow(state[:,:,n_stack-i-1], vmin=-2, vmax=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SubprocVecEnv([make_env(i, env_name, n_stack, n_skip) for i in range(6)])\n",
    "env = VecMonitor(env, LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_ewc = DummyVecEnv([make_env(0, \"SuperMarioBros-1-1-v0\", n_stack, n_skip)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the learning rate\n",
    "def linear_schedule(initial_value: float):\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the trainnig files and logging files location\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        # Save the model and track training progress\n",
    "        if self.num_timesteps % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.num_timesteps))\n",
    "            self.model.save(model_path, exclude=['ewc', 'env_ewc'])\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO.load(os.path.join(CHECKPOINT_DIR, 'best_model_2000040'), env, tensorboard_log=LOG_DIR)\n",
    "#model = PPO('MlpPolicy', env, tensorboard_log='./logs/WithRAMWrapper/linear_learning_rate', verbose=0, learning_rate=linear_schedule(3e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/WithRAMWrapper/model_1/world_1_stage_1/best_model_4700094', env=env, env_ewc=env_ewc, custom_objects={'learning_rate': linear_schedule(2e-4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env_ewc.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\John\\anaconda3\\envs\\super_mario_env\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    }
   ],
   "source": [
    "model._instantiate_ewc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_obs = torch.tensor(state, dtype=torch.float32, device='cuda')\n",
    "features = model.policy.features_extractor(batch_obs)\n",
    "features = model.policy.features_extractor(batch_obs)\n",
    "actor_data = model.policy.mlp_extractor.forward_actor(features)\n",
    "critic_data = model.policy.mlp_extractor.forward_critic(features)\n",
    "actor_logits = model.policy.action_net(actor_data)\n",
    "value_estimates = model.policy.value_net(critic_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9996, -1.0000, -0.4641, -0.9938,  1.0000, -1.0000,  0.8914,  0.9990,\n",
       "         -0.9829, -1.0000, -0.9472, -0.5598,  0.0319,  1.0000, -1.0000, -1.0000,\n",
       "          0.9887,  1.0000, -0.9999, -0.9153,  1.0000, -0.9651, -0.7749, -1.0000,\n",
       "         -0.9998, -1.0000, -0.7749,  0.9395, -1.0000,  0.9998,  0.3940,  0.7203,\n",
       "         -0.9986, -0.9473, -1.0000, -0.9988,  1.0000,  1.0000, -0.9611, -1.0000,\n",
       "         -0.9980, -0.9968,  0.9464, -0.9998,  1.0000,  0.9999,  0.9852, -1.0000,\n",
       "         -1.0000, -1.0000, -0.9278,  1.0000, -1.0000, -0.9007, -0.7828, -1.0000,\n",
       "          1.0000, -1.0000, -0.9995, -0.9729, -1.0000,  0.8833, -1.0000,  0.9996]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (shared_net): Sequential()\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=832, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=832, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=7, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tensorboard_log = './logs/WithRAMWrapper/linear_learning_rate/model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tensorboard_log = './logs/WithRAMWrapper/linear_learning_rate/model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of trained and logged files \n",
    "CHECKPOINT_DIR = './train/WithRAMWrapper/model_1/world_1_stage_2_try_11'\n",
    "LOG_DIR = './logs'\n",
    "HPO_LOG_DIR = './opt_logs'\n",
    "HPO_CHECKPOINT_DIR = './opt_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=100002, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1e7, callback=callback, tb_log_name=\"model_1_nivel_2_try_11\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_mario_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
