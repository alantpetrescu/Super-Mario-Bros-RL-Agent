{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and import the game and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the super mario game in the notebook\n",
    "import gym_super_mario_bros\n",
    "\n",
    "#Import the Joypad wrapper in the notebook\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "#Import the simple controls so that the model just needs to control some movements of our agent (here Mario)\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes the game from colour image (RGB) to grayscale so that our processing becomes faster as we need to deal with less data \n",
    "from gym import ObservationWrapper\n",
    "from gym.spaces import Box\n",
    "\n",
    "# VecFrameStack allows us to work with our stacked enviroments by letting us know the information of previous frames. DummyVecEnv transforms our model so that we can pass it to our AI model. \n",
    "from stable_baselines3.common.vec_env import VecFrameStack, SubprocVecEnv, VecMonitor, VecNormalize\n",
    "\n",
    "# Import the Super Mario RAM utils\n",
    "from Super_Mario_RAM_utils import MarioRAMGrid\n",
    "\n",
    "# Import Numpy for mathematics\n",
    "import numpy as np\n",
    "\n",
    "# Import pyplot for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import time for measuring the training time\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the optimization frame - HPO\n",
    "# import optuna\n",
    "# Bring in the eval policy method for metric calculation\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import gc\n",
    "# Import os for file path management\n",
    "import os\n",
    "\n",
    "# Import PPO algorithm to train our model\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Import Base Callback for saving models and to continue from there\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAMAndSkipWrapper(ObservationWrapper):\n",
    "    def __init__(self, env, n_stack=4, n_skip=2):\n",
    "        super().__init__(env)\n",
    "        self.n_stack = n_stack\n",
    "        self.n_skip = n_skip\n",
    "        self.width = 16\n",
    "        self.height = 13\n",
    "        self.observation_space = Box(\n",
    "            low=-2, high=2, shape=(self.height, self.width, self.n_stack), dtype=np.int8\n",
    "        )\n",
    "        \n",
    "        self.frame_stack = np.zeros((self.height, self.width, (self.n_stack-1)*self.n_skip+1), dtype=np.int8)\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        grid = MarioRAMGrid(self.env)\n",
    "        frame = grid.rendered_screen # The RAM map for the current frame\n",
    "        \n",
    "        self.frame_stack[:,:,1:] = self.frame_stack[:,:,:-1] # Shift frame_stack by 1 to the right\n",
    "        self.frame_stack[:,:,0] = frame # Add the current frame to stack on the left\n",
    "        obs = self.frame_stack[:,:,::self.n_skip]\n",
    "        return obs\n",
    "    \n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        self.frame_stack = np.zeros((self.height, self.width, (self.n_stack-1)*self.n_skip+1), dtype=np.int8)\n",
    "        grid = MarioRAMGrid(self.env)\n",
    "        frame = grid.rendered_screen # 2d array\n",
    "\n",
    "        for i in range(self.frame_stack.shape[-1]):\n",
    "            self.frame_stack[:,:,i] = frame\n",
    "\n",
    "        obs = self.frame_stack[:,:,::self.n_skip]\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(seed, env_name, n_stack, n_skip):\n",
    "    def init():\n",
    "        env = gym_super_mario_bros.make(env_name)\n",
    "        env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "        env = RAMAndSkipWrapper(env, n_stack=n_stack, n_skip=n_skip)\n",
    "\n",
    "        return env\n",
    "    \n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of trained and logged files \n",
    "CHECKPOINT_DIR = './train/WithSkipWrapper'\n",
    "LOG_DIR = './logs'\n",
    "HPO_LOG_DIR = './opt_logs'\n",
    "HPO_CHECKPOINT_DIR = './opt_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"SuperMarioBros-1-2-v0\"\n",
    "n_stack = 4\n",
    "n_skip = 4\n",
    "\n",
    "env = make_env(0, env_name, n_stack, n_skip)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 16, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test env_wrap\n",
    "done = True\n",
    "for i in range(150):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, n_stack, figsize=(14,10))\n",
    "for i in range(n_stack):\n",
    "    ax[i].imshow(state[:,:,n_stack-i-1], vmin=-2, vmax=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SubprocVecEnv([make_env(i, env_name, n_stack, n_skip) for i in range(6)])\n",
    "env = VecMonitor(env, LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the learning rate\n",
    "def linear_schedule(initial_value: float):\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "\n",
    "    :param initial_value: Initial learning rate.\n",
    "    :return: schedule that computes\n",
    "      current learning rate depending on remaining progress\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "        :param progress_remaining:\n",
    "        :return: current learning rate\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the trainnig files and logging files location\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        # Save the model and track training progress\n",
    "        if self.num_timesteps % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.num_timesteps))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO.load(os.path.join(CHECKPOINT_DIR, 'best_model_2000040'), env, tensorboard_log=LOG_DIR)\n",
    "model = PPO('MlpPolicy', env, tensorboard_log='./logs/WithRAMWrapper/linear_learning_rate', verbose=0, learning_rate=linear_schedule(3e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/WithRAMWrapper/model_1/world_1_stage_1/best_model_4700094', env=env, custom_objects={'learning_rate': linear_schedule(1e-4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tensorboard_log = './logs/WithRAMWrapper/linear_learning_rate/model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/WithRAMWrapper/linear_learning_rate/model_1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensorboard_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of trained and logged files \n",
    "CHECKPOINT_DIR = './train/WithRAMWrapper/model_1/world_1_stage_2_try_2'\n",
    "LOG_DIR = './logs'\n",
    "HPO_LOG_DIR = './opt_logs'\n",
    "HPO_CHECKPOINT_DIR = './opt_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=100002, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "model.learn(total_timesteps=5e6, callback=callback, tb_log_name=\"model_1_nivel_2_try_2\")\n",
    "\n",
    "t_elapsed = time.time() - t_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super_mario_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
